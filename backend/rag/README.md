# RAG (Retrieval-Augmented Generation) ëª¨ë“ˆ

ì´ í´ë”ëŠ” RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë¬¸ì„œ ê²€ìƒ‰ ë° ìƒì„±(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•˜ì—¬, ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  LLMì„ í†µí•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ“ í´ë” êµ¬ì¡°

```
rag/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ chunking/          # í…ìŠ¤íŠ¸ ì²­í‚¹ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ chunker.py     # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
â”œâ”€â”€ embedding/         # ì„ë² ë”© ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ embedder.py   # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
â”œâ”€â”€ retrieval/        # ê²€ìƒ‰ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ retriever.py  # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
â”œâ”€â”€ llm/              # LLM ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_client.py # LLM API í´ë¼ì´ì–¸íŠ¸
â”‚   â””â”€â”€ prompts.py    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ parsers/          # íŒŒì¼ íŒŒì„œ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_parser.py      # ë²”ìš© íŒŒì¼ íŒŒì„œ
â”‚   â””â”€â”€ law_table_parser.py # ë²•ë ¹ í…Œì´ë¸” ì „ìš© íŒŒì„œ
â””â”€â”€ utils/            # ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
    â”œâ”€â”€ __init__.py
    â””â”€â”€ retry.py      # ì¬ì‹œë„ ë¡œì§
```

## ğŸ”„ RAG íŒŒì´í”„ë¼ì¸ íë¦„

```
ë¬¸ì„œ ì—…ë¡œë“œ
    â†“
íŒŒì¼ íŒŒì‹± (parsers/)
    â†“
í…ìŠ¤íŠ¸ ì²­í‚¹ (chunking/)
    â†“
ì„ë² ë”© ìƒì„± (embedding/)
    â†“
ë²¡í„° ì €ì¥ì†Œ ì €ì¥ (retrieval/)
    â†“
[ì‚¬ìš©ì ì§ˆë¬¸]
    â†“
ì§ˆë¬¸ ì„ë² ë”© ìƒì„± (embedding/)
    â†“
ìœ ì‚¬ë„ ê²€ìƒ‰ (retrieval/)
    â†“
ê´€ë ¨ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
    â†“
LLM ë‹µë³€ ìƒì„± (llm/)
    â†“
ìµœì¢… ë‹µë³€ ë°˜í™˜
```

## ğŸ“¦ ëª¨ë“ˆ ìƒì„¸ ì„¤ëª…

### 1. `chunking/chunker.py` - í…ìŠ¤íŠ¸ ì²­í‚¹

í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í• í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

#### ì£¼ìš” ê¸°ëŠ¥
- **ë¬¸ì¥ ë‹¨ìœ„ ì²­í‚¹**: ë¬¸ì¥ êµ¬ë¶„ì(`.`, `!`, `?`)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• 
- **ì¤„ ë‹¨ìœ„ ì²­í‚¹**: ë¬¸ì¥ êµ¬ë¶„ìê°€ ì—†ëŠ” ê²½ìš° ì¤„ë°”ê¿ˆ(`\n`)ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
- **í–‰ ë‹¨ìœ„ ì²­í‚¹**: êµ¬ì¡°í™”ëœ ë°ì´í„°(CSV, Excel)ì˜ ê²½ìš° í–‰ ë‹¨ìœ„ë¡œ ë¶„í• 
- **ì˜¤ë²„ë© ì²˜ë¦¬**: ì²­í¬ ê°„ ì—°ì†ì„±ì„ ìœ„í•´ ì¼ì • ê¸¸ì´ë§Œí¼ ì˜¤ë²„ë© í—ˆìš©

#### í´ë˜ìŠ¤: `Chunker`

```python
Chunker(
    chunk_size: int = 1000,      # ì²­í¬ ìµœëŒ€ í¬ê¸° (ë¬¸ì ìˆ˜)
    chunk_overlap: int = 200,     # ì²­í¬ ê°„ ì˜¤ë²„ë© í¬ê¸°
    chunk_by_row: bool = False    # í–‰ ë‹¨ìœ„ ì²­í‚¹ ì—¬ë¶€
)
```

#### ì£¼ìš” ë©”ì„œë“œ

- `chunk_text(text: str, metadata: Optional[Dict]) -> List[str]`
  - í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„í• 
  - `metadata`ì— `is_structured_data=True`ê°€ ìˆìœ¼ë©´ í–‰ ë‹¨ìœ„ ì²­í‚¹ ìˆ˜í–‰

- `_chunk_by_row(text: str) -> List[str]`
  - í–‰ ë‹¨ìœ„ ì²­í‚¹ (CSV/Excel ë°ì´í„°ìš©)
  - `'í–‰ '`ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì„ ìƒˆë¡œìš´ ì²­í¬ì˜ ì‹œì‘ìœ¼ë¡œ ì¸ì‹

- `update_config(chunk_size, chunk_overlap, chunk_by_row)`
  - ì²­í‚¹ ì„¤ì •ì„ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.chunking.chunker import Chunker

chunker = Chunker(chunk_size=1000, chunk_overlap=200)
chunks = chunker.chunk_text("ê¸´ í…ìŠ¤íŠ¸ ë‚´ìš©...")
```

---

### 2. `embedding/embedder.py` - í…ìŠ¤íŠ¸ ì„ë² ë”©

í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

#### ì£¼ìš” ê¸°ëŠ¥
- **OpenAI Embedding API ì‚¬ìš©**: `text-embedding-3-small` ëª¨ë¸ ì‚¬ìš©
- **ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©**: í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
- **ë°°ì¹˜ ì„ë² ë”©**: ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì„ë² ë”© (íš¨ìœ¨ì„± í–¥ìƒ)
- **ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°**: ë‘ ë²¡í„° ê°„ì˜ ìœ ì‚¬ë„ ì¸¡ì •
- **ì¬ì‹œë„ ë¡œì§**: API ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)

#### í´ë˜ìŠ¤: `Embedder`

```python
Embedder(
    api_key: str,                    # OpenAI API í‚¤
    model: str = "text-embedding-3-small"  # ì„ë² ë”© ëª¨ë¸
)
```

#### ì£¼ìš” ë©”ì„œë“œ

- `embed_text(text: str) -> List[float]`
  - ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
  - ë¹ˆ í…ìŠ¤íŠ¸ëŠ” `ValueError` ë°œìƒ

- `embed_query(query: str) -> List[float]`
  - ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© (ë‚´ë¶€ì ìœ¼ë¡œ `embed_text` í˜¸ì¶œ)

- `embed_batch(texts: List[str]) -> List[List[float]]`
  - ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ì„ë² ë”©
  - ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ìë™ìœ¼ë¡œ í•„í„°ë§

- `cosine_similarity(vec1: List[float], vec2: List[float]) -> float`
  - ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (0~1 ë²”ìœ„)
  - ìœ ì‚¬ë„ê°€ ë†’ì„ìˆ˜ë¡ 1ì— ê°€ê¹Œì›€

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.embedding.embedder import Embedder

embedder = Embedder(api_key="your-api-key")
vector = await embedder.embed_text("í…ìŠ¤íŠ¸ ë‚´ìš©")
similarity = embedder.cosine_similarity(vec1, vec2)
```

---

### 3. `retrieval/retriever.py` - ë²¡í„° ê²€ìƒ‰

ë²¡í„° ì €ì¥ì†Œì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

#### ì£¼ìš” ê¸°ëŠ¥
- **ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ**: JSON íŒŒì¼ë¡œ ë²¡í„° ì €ì¥ ë° ë¡œë“œ
- **ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰**: ì¿¼ë¦¬ ë²¡í„°ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
- **ë©”íƒ€ë°ì´í„° í•„í„°ë§**: í´ë”, íŒŒì¼ëª… ë“±ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ ì œí•œ
- **ì ìˆ˜ ë¶€ìŠ¤íŒ…**: ì‹œë‚˜ë¦¬ì˜¤/ìš©ë„ ì¼ì¹˜ ì‹œ ì ìˆ˜ ê°€ì¤‘ì¹˜ ì ìš©
- **ì•ˆì „í•œ ì˜¤ë¥˜ ì²˜ë¦¬**: ì†ìƒëœ JSON íŒŒì¼ ìë™ ë³µêµ¬

#### í´ë˜ìŠ¤: `Retriever`

```python
Retriever(
    vector_store_path: str = "vector_store",  # ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œ
    top_k: int = 5,                          # ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
    similarity_threshold: float = 0.1,        # ìœ ì‚¬ë„ ì„ê³„ê°’
    similarity_weight: float = 1.0,           # ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜
    recency_weight: float = 0.0,              # ìµœì‹ ì„± ê°€ì¤‘ì¹˜
    source_weight: float = 0.0                # ì¶œì²˜ ê°€ì¤‘ì¹˜
)
```

#### ì£¼ìš” ë©”ì„œë“œ

- `add_document(embedding, content, metadata)`
  - ë¬¸ì„œë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
  - ìë™ìœ¼ë¡œ JSON íŒŒì¼ì— ì €ì¥

- `retrieve(query_embedding, folder_filter, filename_filter, top_k, similarity_threshold)`
  - ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
  - `folder_filter`: íŠ¹ì • í´ë”ì˜ ë¬¸ì„œë§Œ ê²€ìƒ‰
  - `filename_filter`: íŠ¹ì • íŒŒì¼ëª… íŒ¨í„´ë§Œ ê²€ìƒ‰ (ì˜ˆ: `["4.", "5-1.", "5-2."]`)
  - ì ìˆ˜ ë¶€ìŠ¤íŒ…:
    - ì‹œë‚˜ë¦¬ì˜¤ ì¼ì¹˜: +0.1
    - ìš©ë„ ì¼ì¹˜: +0.05

- `remove_document(doc_id)`
  - íŠ¹ì • ë¬¸ì„œ IDì˜ ëª¨ë“  ì²­í¬ ì œê±°

- `_load_vector_store()`
  - ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
  - JSON íŒŒì‹± ì˜¤ë¥˜ ì‹œ ìë™ ë°±ì—… ë° ë³µêµ¬

- `_save_vector_store()`
  - ë²¡í„° ì €ì¥ì†Œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

#### ë²¡í„° ì €ì¥ì†Œ êµ¬ì¡°

```json
{
  "vectors": [[0.1, 0.2, ...], ...],      // ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
  "contents": ["ì²­í¬ ë‚´ìš©1", ...],        // ì²­í¬ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
  "metadatas": [                          // ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    {
      "source": "doc_id",
      "filename": "5-2.ë²•ë ¹ë³„.doc",
      "folder": "ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ",
      "scenario": "ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ",
      "law_group": "ê±´ì¶•ë²•",
      "item_name": "ê±´ì¶•ë¬¼ì˜ ë†’ì´ ì œí•œ",
      "article_ids": ["ì œ60ì¡°", "ì œ61ì¡°"],
      ...
    },
    ...
  ]
}
```

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.retrieval.retriever import Retriever
from rag.embedding.embedder import Embedder

retriever = Retriever(vector_store_path="./vector_store")
embedder = Embedder(api_key="your-api-key")

# ë¬¸ì„œ ì¶”ê°€
embedding = await embedder.embed_text("ë¬¸ì„œ ë‚´ìš©")
await retriever.add_document(
    embedding=embedding,
    content="ë¬¸ì„œ ë‚´ìš©",
    metadata={"filename": "test.txt", "folder": "folder1"}
)

# ê²€ìƒ‰
query_embedding = await embedder.embed_query("ê²€ìƒ‰ ì§ˆë¬¸")
results = await retriever.retrieve(
    query_embedding=query_embedding,
    folder_filter="ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ",
    filename_filter=["5-2."],
    top_k=5
)
```

---

### 4. `llm/llm_client.py` - LLM ë‹µë³€ ìƒì„±

ê²€ìƒ‰ëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì„ í†µí•´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

#### ì£¼ìš” ê¸°ëŠ¥
- **OpenAI Chat API ì‚¬ìš©**: `gpt-4o-mini` ëª¨ë¸ ì‚¬ìš©
- **êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ ì§€ì›**: ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ëœ ì²­í¬ë¥¼ í¬ë§·íŒ…
- **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**: `prompts.py`ì˜ í…œí”Œë¦¿ ì‚¬ìš©
- **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ**: 12000ì ì´ˆê³¼ ì‹œ ìë™ ì¶•ì•½
- **ì¬ì‹œë„ ë¡œì§**: API ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„

#### í´ë˜ìŠ¤: `LLMClient`

```python
LLMClient(
    api_key: str,                    # OpenAI API í‚¤
    model: str = "gpt-4o-mini"        # LLM ëª¨ë¸
)
```

#### ì£¼ìš” ë©”ì„œë“œ

- `generate_answer(query, context, chunks, scenario) -> str`
  - ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
  - `chunks`ê°€ ì œê³µë˜ë©´ êµ¬ì¡°í™”ëœ í¬ë§·íŒ… ì‚¬ìš©
  - `context`ê°€ ì œê³µë˜ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
  - `scenario`: ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ (í”„ë¡¬í”„íŠ¸ì— í¬í•¨)

#### íŒŒë¼ë¯¸í„°
- `max_tokens`: 3000 (ê¸´ ë‹µë³€ ìƒì„±)
- `temperature`: 0.3 (ì¼ê´€ëœ ë‹µë³€)

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.llm.llm_client import LLMClient

llm_client = LLMClient(api_key="your-api-key")

# êµ¬ì¡°í™”ëœ ì²­í¬ ì‚¬ìš©
answer = await llm_client.generate_answer(
    query="ê±´ì¶•í—ˆê°€ì— í•„ìš”í•œ ì„œë¥˜ëŠ”?",
    chunks=[
        {
            "scenario": "ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ",
            "law_group": "ê±´ì¶•ë²•",
            "item_name": "ê±´ì¶•í—ˆê°€ ì‹ ì²­",
            "review_text": "ê²€í† ë‚´ìš©...",
            "law_text": "ë²•ë ¹ë‚´ìš©...",
            ...
        }
    ],
    scenario="ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ"
)

# ì¼ë°˜ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
answer = await llm_client.generate_answer(
    query="ì§ˆë¬¸",
    context="ì°¸ê³  ë¬¸ì„œ ë‚´ìš©..."
)
```

---

### 5. `llm/prompts.py` - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

#### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

- **`SYSTEM_PROMPT`**: ì‹œìŠ¤í…œ ì—­í•  ì •ì˜
  - ê±´ì¶• ì¸í—ˆê°€ ì‹¤ë¬´ë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸
  - ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€, ì¶”ì¸¡ ê¸ˆì§€

- **`USER_PROMPT_TEMPLATE`**: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
  - ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ í¬í•¨
  - ê²€í† ë‚´ìš©ê³¼ ë²•ë ¹ë‚´ìš© êµ¬ë¶„
  - ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë‹µë³€ ìš”êµ¬

- **`get_rag_prompt(query, context, scenario) -> str`**
  - RAG í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
  - ì¿¼ë¦¬, ì»¨í…ìŠ¤íŠ¸, ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¡°í•©

- **`format_context_chunks(chunks) -> str`**
  - êµ¬ì¡°í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
  - ê° ì²­í¬ì˜ ë©”íƒ€ë°ì´í„°(ì‹œë‚˜ë¦¬ì˜¤, ë²•ë ¹ ë¬¶ìŒ, í•­ëª©, ì¡°ë¬¸, ê²€í† ë‚´ìš©, ë²•ë ¹ë‚´ìš©) í¬í•¨

#### í”„ë¡¬í”„íŠ¸ êµ¬ì¡°

```
[ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸]
ë‹¹ì‹ ì€ ê±´ì¶• ì¸í—ˆê°€ ì‹¤ë¬´ë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì°¸ê³  ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
...

[ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸]
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê±´ì¶• ì¸í—ˆê°€ ì‹¤ë¬´ë¥¼ ë•ëŠ” AIì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” "{scenario}" ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ë²•ë ¹ ì¡°ë¬¸ê³¼ ê²€í† ë‚´ìš©ì…ë‹ˆë‹¤.

[ì°¸ê³  ìë£Œ]
[ì°¸ê³  ìë£Œ 1]
ì‹œë‚˜ë¦¬ì˜¤: ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ
ë²•ë ¹ ë¬¶ìŒ: ê±´ì¶•ë²•
í•­ëª©: ê±´ì¶•ë¬¼ì˜ ë†’ì´ ì œí•œ
ì¡°ë¬¸: ì œ60ì¡°, ì œ61ì¡°
ê²€í† ë‚´ìš©: ...
ë²•ë ¹ë‚´ìš©: ...

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ìœ„ ìë£Œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•´ì„œ í•œêµ­ì–´ë¡œ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
```

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.llm.prompts import get_rag_prompt, format_context_chunks

# êµ¬ì¡°í™”ëœ ì²­í¬ í¬ë§·íŒ…
context = format_context_chunks(chunks)

# í”„ë¡¬í”„íŠ¸ ìƒì„±
prompt = get_rag_prompt(
    query="ê±´ì¶•í—ˆê°€ì— í•„ìš”í•œ ì„œë¥˜ëŠ”?",
    context=context,
    scenario="ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ"
)
```

---

### 6. `parsers/file_parser.py` - ë²”ìš© íŒŒì¼ íŒŒì„œ

ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

#### ì§€ì› íŒŒì¼ í˜•ì‹
- **Excel** (`.xlsx`, `.xls`): pandasë¡œ ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
- **CSV** (`.csv`): pandasë¡œ ì½ê¸°
- **Word** (`.docx`): python-docxë¡œ ì½ê¸°
- **Word (êµ¬ë²„ì „)** (`.doc`): HTML í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš° BeautifulSoupìœ¼ë¡œ íŒŒì‹±
- **í…ìŠ¤íŠ¸** (`.txt`, `.md`): UTF-8 ë””ì½”ë”©
- **HTML**: í…ìŠ¤íŠ¸ ì¶”ì¶œ

#### í´ë˜ìŠ¤: `FileParser`

#### ì£¼ìš” ë©”ì„œë“œ

- `parse_file(filename: str, file_content: bytes) -> str`
  - íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ íŒŒì„œ í˜¸ì¶œ
  - ë°˜í™˜: í…ìŠ¤íŠ¸ ë¬¸ìì—´

- `_parse_excel(file_content: bytes) -> str`
  - Excel íŒŒì¼ íŒŒì‹±
  - ëª¨ë“  ì‹œíŠ¸ë¥¼ ì½ì–´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

- `_parse_csv(file_content: bytes, filename: str) -> str`
  - CSV íŒŒì¼ íŒŒì‹±
  - ì¸ì½”ë”© ìë™ ê°ì§€ (UTF-8, CP949, EUC-KR)

- `_parse_docx(file_content: bytes) -> str`
  - Word ë¬¸ì„œ(.docx) íŒŒì‹±
  - ë‹¨ë½ê³¼ í‘œ ì¶”ì¶œ

- `_parse_doc(file_content: bytes, filename: str) -> str`
  - Word ë¬¸ì„œ(.doc) íŒŒì‹±
  - HTML í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš° BeautifulSoup ì‚¬ìš©

- `_extract_text_from_html(html_content: str) -> str`
  - HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  - ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼ íƒœê·¸ ì œê±°

- `parse_law_table_file(filename: str, file_content: bytes) -> List[Dict]`
  - `5-2.ë²•ë ¹ë³„` ë¬¸ì„œ ì „ìš© íŒŒì„œ
  - `LawTableParser` ì‚¬ìš©

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.parsers.file_parser import FileParser

with open("document.xlsx", "rb") as f:
    content = f.read()

text = FileParser.parse_file("document.xlsx", content)
```

---

### 7. `parsers/law_table_parser.py` - ë²•ë ¹ í…Œì´ë¸” íŒŒì„œ

`5-2.ë²•ë ¹ë³„` ë¬¸ì„œë¥¼ í–‰ ë‹¨ìœ„ë¡œ êµ¬ì¡°í™”í•˜ì—¬ íŒŒì‹±í•˜ëŠ” ì „ìš© íŒŒì„œì…ë‹ˆë‹¤.

#### ì£¼ìš” ê¸°ëŠ¥
- **HTML í…Œì´ë¸” íŒŒì‹±**: BeautifulSoupìœ¼ë¡œ HTML í…Œì´ë¸” ì¶”ì¶œ
- **í–‰ ë‹¨ìœ„ êµ¬ì¡°í™”**: ê° í…Œì´ë¸” í–‰ì„ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ì²˜ë¦¬
- **ë©”íƒ€ë°ì´í„° ì¶”ì¶œ**: ë²•ë ¹ ë¬¶ìŒ, í•­ëª©ëª…, ì¡°ë¬¸ ë²ˆí˜¸, ê²€í† ë‚´ìš©, ë²•ë ¹ë‚´ìš© ë“±
- **ì„ë² ë”© í…ìŠ¤íŠ¸ ìƒì„±**: êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

#### í´ë˜ìŠ¤: `LawTableParser`

#### ì£¼ìš” ë©”ì„œë“œ

- `parse_law_table(html_content: str, scenario: str, filename: str) -> List[Dict]`
  - HTML í…Œì´ë¸”ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
  - ê° í–‰ì€ í•˜ë‚˜ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

- `_parse_row(cells, scenario, law_group, filename) -> Dict`
  - í…Œì´ë¸” í–‰ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ì²­í¬ ë©”íƒ€ë°ì´í„° ìƒì„±

- `_extract_law_content(cell) -> tuple[str, List[str]]`
  - ë²•ë ¹ë‚´ìš© ì…€ì—ì„œ ë²•ë ¹ í…ìŠ¤íŠ¸ì™€ ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì¶œ
  - `jonote` í´ë˜ìŠ¤ì—ì„œ ì¡°ë¬¸ ì œëª© ì¶”ì¶œ
  - `tag1`, `tag2`, `tag3`, `tag4` í´ë˜ìŠ¤ì—ì„œ ì¡°ë¬¸ ë‚´ìš© ì¶”ì¶œ

- `_extract_review_content(cell) -> tuple[str, Dict]`
  - ê²€í† ë‚´ìš© ì…€ì—ì„œ ê²€í†  í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
  - `note1` í´ë˜ìŠ¤ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ê±´ì¶•ì¢…ë¥˜, ê±´ì¶•ë¬¼ìš©ë„, ê±´ì¶•ì£¼, ì£¼ìš”êµ¬ì¡°ë¶€, ê±´ë¬¼íŠ¹ì„±)
  - `note2` í´ë˜ìŠ¤ì—ì„œ ê²€í† ë‚´ìš© ì¶”ì¶œ

- `create_embedding_text(chunk: Dict) -> str`
  - êµ¬ì¡°í™”ëœ ì²­í¬ë¥¼ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
  - ì‹œë‚˜ë¦¬ì˜¤, ë²•ë ¹ ë¬¶ìŒ, ì¡°ë¬¸, í•­ëª©, ê²€í† ë‚´ìš©, ë²•ë ¹ë‚´ìš©, ìš©ë„, ê±´ì¶•ì¢…ë¥˜ í¬í•¨

#### ë°˜í™˜ ë°ì´í„° êµ¬ì¡°

```python
{
    "id": "scenario|filename|law_group|no",
    "scenario": "ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ",
    "law_group": "ê±´ì¶•ë²•",
    "article_ids": ["ì œ60ì¡°", "ì œ61ì¡°"],
    "item_name": "ê±´ì¶•ë¬¼ì˜ ë†’ì´ ì œí•œ",
    "law_text": "ë²•ë ¹ ì¡°ë¬¸ ì›ë¬¸...",
    "review_text": "ê²€í† ë‚´ìš© ìš”ì•½...",
    "no": 1,
    "filename": "5-2.ë²•ë ¹ë³„.doc",
    "building_type": "ì‹ ì¶•",
    "usage": "ê³µë™ì£¼íƒ",
    "owner_type": "ì¼ë°˜ê°œì¸",
    "main_structure": "ì² ê·¼ì½˜í¬ë¦¬íŠ¸",
    "building_characteristics": ["íŠ¹ì„±1", "íŠ¹ì„±2"]
}
```

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.parsers.law_table_parser import LawTableParser

with open("5-2.ë²•ë ¹ë³„.doc", "rb") as f:
    html_content = f.read().decode('utf-8')

chunks = LawTableParser.parse_law_table(
    html_content=html_content,
    scenario="ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ",
    filename="5-2.ë²•ë ¹ë³„.doc"
)

# ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±
for chunk in chunks:
    embed_text = LawTableParser.create_embedding_text(chunk)
```

---

### 8. `utils/retry.py` - ì¬ì‹œë„ ìœ í‹¸ë¦¬í‹°

API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¬ì‹œë„í•˜ëŠ” ë°ì½”ë ˆì´í„°ì…ë‹ˆë‹¤.

#### ì£¼ìš” ê¸°ëŠ¥
- **ì§€ìˆ˜ ë°±ì˜¤í”„**: ì¬ì‹œë„ ê°„ê²©ì´ ì§€ìˆ˜ì ìœ¼ë¡œ ì¦ê°€
- **ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •**: ê¸°ë³¸ 3íšŒ
- **ì˜ˆì™¸ íƒ€ì… ì§€ì •**: íŠ¹ì • ì˜ˆì™¸ë§Œ ì¬ì‹œë„
- **ìµœëŒ€ ì§€ì—° ì‹œê°„ ì œí•œ**: ì§€ì—° ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ ì œí•œ

#### í•¨ìˆ˜: `retry_with_backoff`

```python
@retry_with_backoff(
    max_retries: int = 3,              # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    initial_delay: float = 1.0,        # ì´ˆê¸° ì§€ì—° ì‹œê°„ (ì´ˆ)
    max_delay: float = 10.0,           # ìµœëŒ€ ì§€ì—° ì‹œê°„ (ì´ˆ)
    exponential_base: float = 2.0,     # ì§€ìˆ˜ ì¦ê°€ ê¸°ì¤€
    exceptions: tuple = (Exception,)    # ì¬ì‹œë„í•  ì˜ˆì™¸ íƒ€ì…
)
```

#### ì¬ì‹œë„ ë¡œì§
1. ì²« ë²ˆì§¸ ì‹¤íŒ¨: `initial_delay` ì´ˆ ëŒ€ê¸°
2. ë‘ ë²ˆì§¸ ì‹¤íŒ¨: `initial_delay * exponential_base` ì´ˆ ëŒ€ê¸°
3. ì„¸ ë²ˆì§¸ ì‹¤íŒ¨: `initial_delay * exponential_base^2` ì´ˆ ëŒ€ê¸°
4. ìµœëŒ€ ì§€ì—° ì‹œê°„ì€ `max_delay`ë¡œ ì œí•œ

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.utils.retry import retry_with_backoff
from openai import APIError, RateLimitError

@retry_with_backoff(
    max_retries=3,
    initial_delay=1.0,
    max_delay=10.0,
    exceptions=(APIError, RateLimitError)
)
async def call_api():
    # API í˜¸ì¶œ ì½”ë“œ
    pass
```

---

## ğŸ”§ ì„¤ì • ë° ì‚¬ìš©ë²•

### í™˜ê²½ ë³€ìˆ˜

```bash
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_DOCUMENTS=5
SIMILARITY_THRESHOLD=0.3
```

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì˜ˆì‹œ

```python
from rag.chunking.chunker import Chunker
from rag.embedding.embedder import Embedder
from rag.retrieval.retriever import Retriever
from rag.llm.llm_client import LLMClient
from rag.parsers.file_parser import FileParser

# 1. ë¬¸ì„œ íŒŒì‹±
with open("document.docx", "rb") as f:
    content = FileParser.parse_file("document.docx", f.read())

# 2. í…ìŠ¤íŠ¸ ì²­í‚¹
chunker = Chunker(chunk_size=1000, chunk_overlap=200)
chunks = chunker.chunk_text(content)

# 3. ì„ë² ë”© ìƒì„± ë° ì €ì¥
embedder = Embedder(api_key="your-api-key")
retriever = Retriever(vector_store_path="./vector_store")

for chunk in chunks:
    embedding = await embedder.embed_text(chunk)
    await retriever.add_document(
        embedding=embedding,
        content=chunk,
        metadata={"filename": "document.docx"}
    )

# 4. ì§ˆë¬¸ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
query = "ê±´ì¶•í—ˆê°€ì— í•„ìš”í•œ ì„œë¥˜ëŠ”?"
query_embedding = await embedder.embed_query(query)

results = await retriever.retrieve(
    query_embedding=query_embedding,
    folder_filter="ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ",
    top_k=5
)

llm_client = LLMClient(api_key="your-api-key")
answer = await llm_client.generate_answer(
    query=query,
    chunks=results,
    scenario="ì‹ ì¶•_ì¼ë°˜ê°œì¸_ë‹¤ì¤‘ì£¼íƒ"
)
```

## ğŸ“ ì£¼ìš” íŠ¹ì§•

1. **êµ¬ì¡°í™”ëœ ì²­í‚¹**: ë²•ë ¹ í…Œì´ë¸” ë¬¸ì„œëŠ” í–‰ ë‹¨ìœ„ë¡œ êµ¬ì¡°í™”í•˜ì—¬ íŒŒì‹±
2. **ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§**: í´ë”, íŒŒì¼ëª…, ì‹œë‚˜ë¦¬ì˜¤ ë“±ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ ì œí•œ
3. **ì ìˆ˜ ë¶€ìŠ¤íŒ…**: ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œì— ê°€ì¤‘ì¹˜ ì ìš©
4. **ì•ˆì „í•œ ì˜¤ë¥˜ ì²˜ë¦¬**: API ì˜¤ë¥˜, íŒŒì¼ ì†ìƒ ë“±ì— ëŒ€í•œ ìë™ ë³µêµ¬
5. **ë¹„ë™ê¸° ì²˜ë¦¬**: ëª¨ë“  API í˜¸ì¶œì€ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
6. **ì¬ì‹œë„ ë¡œì§**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

- **ë°°ì¹˜ ì„ë² ë”©**: ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì„ë² ë”©í•˜ì—¬ API í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ
- **ë©”ëª¨ë¦¬ ê¸°ë°˜ ì €ì¥ì†Œ**: ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë©”ëª¨ë¦¬ ë²¡í„° ì €ì¥
- **ë¹„ë™ê¸° ì²˜ë¦¬**: I/O ì‘ì—…ì˜ ë³‘ë ¬ ì²˜ë¦¬
- **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ**: LLM í† í° ì œí•œì„ ê³ ë ¤í•œ ìë™ ì¶•ì•½

## ğŸ” ë””ë²„ê¹…

ê° ëª¨ë“ˆì€ ë¡œê¹…ì„ ì§€ì›í•©ë‹ˆë‹¤. ë¡œê·¸ ë ˆë²¨ì„ ì„¤ì •í•˜ì—¬ ë””ë²„ê¹… ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“š ì°¸ê³  ìë£Œ

- OpenAI Embedding API: https://platform.openai.com/docs/guides/embeddings
- OpenAI Chat API: https://platform.openai.com/docs/guides/text-generation
- FastAPI: https://fastapi.tiangolo.com/

